{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epbehren3/bilinear_resizer/blob/Main/Learning_Resizer_Model_ECE570.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a0qCl1K89nMs"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from os import EX_PROTOCOL\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose which dataset you would like to train on.\n",
        "\n",
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar -xzf imagenette2.tgz\n",
        "!rm imagenette2.tgz\n",
        "#!wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2.tgz\n",
        "#!tar -xzf imagewoof2.tgz\n",
        "#!rm imagewoof2.tgz"
      ],
      "metadata": {
        "id": "DwAo_dhxd_bA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fa9e7c-474a-40c1-f57a-96a8505c7ef8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-11 03:37:22--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.65.238, 52.217.139.0, 52.216.28.182, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.65.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1557161267 (1.5G) [application/x-tar]\n",
            "Saving to: ‘imagenette2.tgz’\n",
            "\n",
            "imagenette2.tgz     100%[===================>]   1.45G  58.8MB/s    in 27s     \n",
            "\n",
            "2024-11-11 03:37:49 (55.4 MB/s) - ‘imagenette2.tgz’ saved [1557161267/1557161267]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AYp2PH5NzvEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6bc701-b427-4123-b348-adc5ac3b4d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "#Define Hyperparameters -\n",
        "\n",
        "batchSize = 64\n",
        "#batchSizeTest = 1000\n",
        "maxEpoch = 15\n",
        "learningRate = 0.1\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "resBlocks = 5\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available\")\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  print(\"GPU is not available\")\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xWIAQBi18nou"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Data Loader - Load images into model for training and validation\n",
        "#Redo to use ImageNette\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((320, 320)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for ImageNet\n",
        "])\n",
        "\n",
        "data_path = r'/content/imagenette2'\n",
        "#data_path = r'/content/imagewoof2'\n",
        "#trainDataSet  = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "#testDataSet = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "trainDataset = torchvision.datasets.ImageFolder(root=data_path + '/train', transform=transform)\n",
        "testDataset = torchvision.datasets.ImageFolder(root=data_path + '/val', transform=transform)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "testLoader = torch.utils.data.DataLoader(testDataset, batch_size=batchSize, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ThzDIIg5Cz_1"
      },
      "outputs": [],
      "source": [
        "#ResBlock Model\n",
        "class resBlock(nn.Module):#Resnet Block as defined in original paper.\n",
        "    def __init__(self, channelSize = 16,negativeSlope = 0.02, kernelSize = 3, stride=1):\n",
        "        super(resBlock, self).__init__()\n",
        "\n",
        "\n",
        "      #Define the sequential NN based on the structure listed in our paper\n",
        "        self.convBlock = nn.Sequential(\n",
        "        nn.Conv2d(channelSize,channelSize, kernelSize, stride, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(channelSize),\n",
        "        nn.LeakyReLU(negativeSlope),\n",
        "        nn.Conv2d(channelSize,channelSize, kernelSize, stride, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(channelSize)\n",
        "      ).to(device)\n",
        "\n",
        "    def forward(self, x):#Sum at the end of the resblock\n",
        "        #self.to(device)\n",
        "        return x + self.convBlock(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x-4-v-JFgXmo"
      },
      "outputs": [],
      "source": [
        "# Build my Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class resizingNetwork(nn.Module):\n",
        "    def __init__(self,channelSize = 16, kernelSize = 7,negativeSlope = 0.02, stride=1, inputSize = (320,320),numResBlock = resBlocks ):\n",
        "      super(resizingNetwork, self).__init__()\n",
        "      #Channel Expander to accomodate input channel size to reccomended channel size.\n",
        "      self.channelExpander = nn.Sequential(\n",
        "          nn.Conv2d(in_channels =  3, out_channels = channelSize,kernel_size = 1, stride = stride, padding = 0, bias = False),\n",
        "          nn.BatchNorm2d(num_features = channelSize),\n",
        "      )\n",
        "      #Block1 as defined in the initial structur\n",
        "      self.convBlock1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=channelSize,out_channels = channelSize, kernel_size=kernelSize,stride = stride,padding = 1, bias = False),\n",
        "          nn.LeakyReLU(negative_slope = negativeSlope),\n",
        "          nn.Conv2d(in_channels = channelSize, out_channels=channelSize, kernel_size = 1,stride = stride , padding = 0,bias = False),\n",
        "          nn.BatchNorm2d(num_features = channelSize),\n",
        "          nn.LeakyReLU(negative_slope = negativeSlope),\n",
        "      )\n",
        "      #ResBlocks.\n",
        "      self.blockList = [0] * numResBlock\n",
        "      for r in range(numResBlock):\n",
        "        self.blockList[r] = resBlock()\n",
        "      # Block 2 as defined in the structure\n",
        "      self.convBlock2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = channelSize, out_channels = channelSize, kernel_size = 3, stride = stride,padding = 1, bias = False),\n",
        "          nn.BatchNorm2d(num_features = channelSize),\n",
        "      )\n",
        "      #Block 3 as defined in the structure\n",
        "      self.convBlock3 = nn.Sequential(\n",
        "          #Transitional convolution layer to transform 16 channels into 3\n",
        "          nn.Conv2d(in_channels =  channelSize, out_channels = 3,kernel_size = 1, stride = stride, padding = 0, bias = False),\n",
        "          nn.BatchNorm2d(num_features = 3),\n",
        "          nn.Conv2d(in_channels = 3,out_channels = 3 ,kernel_size = 7, stride = 1, padding = 3, bias  = False)\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      #Initial Interpolation\n",
        "      bilinearOriginal = F.interpolate(x,size = (224,224), mode = 'bilinear', align_corners=False)\n",
        "      #Expansion layer to transform 3 channels (RGB) into 16 for initial input.\n",
        "      x = self.channelExpander(x)\n",
        "      x = self.convBlock1(x)\n",
        "      #Modified Interpolation\n",
        "      x = bilinearModified = F.interpolate(x,size = (224,224), mode = 'bilinear', align_corners=False)\n",
        "      #Apply number of resBlocks\n",
        "      for resBlock in self.blockList:\n",
        "        x = resBlock(x)\n",
        "\n",
        "      x = self.convBlock2(x)\n",
        "      x = x + bilinearModified\n",
        "      x = self.convBlock3(x)\n",
        "      x = x + bilinearOriginal\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#inhereted Resnet 50 Classifier Model\n",
        "\n",
        "class resnet50Classifier(nn.Module):\n",
        "    def __init__(self, numClasses =1000, preTrained = False):\n",
        "        super(resnet50Classifier, self).__init__()\n",
        "\n",
        "        # Load the un-trained ResNet-50 model\n",
        "        self.resnet50 = models.resnet50(weights= preTrained)\n",
        "\n",
        "        # Modify the last fully connected layer to match the number of classes\n",
        "        numFeatures = self.resnet50.fc.in_features\n",
        "        self.resnet50.fc = nn.Linear(numFeatures, numClasses)\n",
        "\n",
        "    def forward(self, x):\n",
        "       # print(\"Number of channels after resizing:\", x.shape[1])\n",
        "        return self.resnet50(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SQEJlkEWbCMa"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Data Trainer - Training process for my resnet model, reimplemented training and testing function that I feveloped for PA3 to train my classification model\n",
        "def train(model: nn.Module,\n",
        "          lossFN: nn.modules.loss._Loss,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          trainLoader: torch.utils.data.DataLoader,\n",
        "          epoch: int=0)-> List:\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(trainLoader):\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = lossFN(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch {epoch}: [{batch_idx*len(images)}/{len(trainLoader.dataset)}] Loss: {loss.item():.3f}')\n",
        "\n",
        "    assert len(train_loss) == len(trainLoader)\n",
        "    return train_loss\n",
        "\n",
        "def test(model: nn.Module,\n",
        "         lossFN: nn.modules.loss._Loss,\n",
        "         testLoader: torch.utils.data.DataLoader,\n",
        "         epoch: int=0)-> Dict:\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_stat = {\n",
        "        \"loss\": 0,\n",
        "        \"accuracy\": 0,\n",
        "        \"prediction\": []\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in testLoader:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(images)\n",
        "            test_stat[\"loss\"] += lossFN(output, targets).item()\n",
        "            test_stat[\"accuracy\"] += (torch.argmax(output, dim=1) == targets).sum().item()\n",
        "            test_stat[\"prediction\"].append(torch.argmax(output, dim=1))\n",
        "\n",
        "    test_stat[\"accuracy\"] /= len(testLoader.dataset)\n",
        "    test_stat[\"accuracy\"] *= 100\n",
        "    test_stat[\"loss\"] /= len(testLoader)\n",
        "    test_stat[\"prediction\"] = torch.cat(test_stat[\"prediction\"])\n",
        "\n",
        "    # dictionary should include loss, accuracy and prediction\n",
        "    print(f\"Accuracy: {test_stat['accuracy']:.4f}%\")\n",
        "\n",
        "    assert \"loss\" and \"accuracy\" and \"prediction\" in test_stat.keys()\n",
        "    # \"prediction\" value should be a 1D tensor\n",
        "    assert len(test_stat[\"prediction\"]) == len(testLoader.dataset)\n",
        "    assert isinstance(test_stat[\"prediction\"], torch.Tensor)\n",
        "    return test_stat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8I4LuekQggA"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FRF6g2dfxDob"
      },
      "outputs": [],
      "source": [
        "#Joint Classifier Model with Learned Resizer, and Untrained Resnet model.\n",
        "class modifiedClassifier(nn.Module):\n",
        "    def __init__(self, resizingNetwork, resnet50Classifier):\n",
        "        super(modifiedClassifier, self).__init__()\n",
        "\n",
        "        self.resizingNetwork = resizingNetwork\n",
        "        self.resnet50Classifier = resnet50Classifier\n",
        "\n",
        "    def forward(self, x):#Feeds through Learned Resizer into the classifier.\n",
        "        x = self.resizingNetwork(x)\n",
        "        x = self.resnet50Classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "absyzwepb6ZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95e0622-113f-4339-81d3-60a65a58693f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "modifiedClassifier(\n",
              "  (resizingNetwork): resizingNetwork(\n",
              "    (channelExpander): Sequential(\n",
              "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (convBlock1): Sequential(\n",
              "      (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): LeakyReLU(negative_slope=0.02)\n",
              "      (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): LeakyReLU(negative_slope=0.02)\n",
              "    )\n",
              "    (convBlock2): Sequential(\n",
              "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (convBlock3): Sequential(\n",
              "      (0): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (resnet50Classifier): resnet50Classifier(\n",
              "    (resnet50): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Define Classifiers\n",
        "\n",
        "#Classifier using traditional Method of Bilinear Interpolation\n",
        "classifierTraditional = resnet50Classifier()\n",
        "classifierTraditional.to(device)\n",
        "\n",
        "#Modified model using Learned Resizer fed into traditional classifier\n",
        "resizerModel = resizingNetwork()\n",
        "resnetModel = resnet50Classifier()\n",
        "classifierModified = modifiedClassifier(resizerModel, resnetModel)\n",
        "classifierModified.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vFX_o357b8q2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "c77e4ccb-2b0d-49bf-a842-0e54460a6569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified:\n",
            "Epoch 1: [0/9469] Loss: 7.020\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-121305182832>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxEpoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#Train and Test both models, record both testing outputs for later use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nModified:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtrainLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifierModified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mtestStat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifierModified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mtestOutMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestStat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9c66d5872fcd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, lossFN, optimizer, trainLoader, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Comparison Model - Classify both Traditional Biliinear Resizer, and Learned Resizer to run, and then compare outputs.\n",
        "optimizer = optim.SGD(classifierModified.parameters(), lr=learningRate, momentum=0.9)\n",
        "optimizerTraditional = optim.SGD(classifierTraditional.parameters(), lr=learningRate, momentum=0.9)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "testOutTrad = []\n",
        "testOutMod = []\n",
        "for epoch in range(1,maxEpoch + 1):#Train and Test both models, record both testing outputs for later use.\n",
        "  print(\"\\nModified:\")\n",
        "  trainLoss = train(classifierModified, nn.CrossEntropyLoss(), optimizer, trainLoader, epoch)\n",
        "  testStat = test(classifierModified, nn.CrossEntropyLoss(), testLoader, epoch)\n",
        "  testOutMod.append(testStat)\n",
        "\n",
        "  print(\"\\nTraditional:\")\n",
        "  trainLossTraditional = train(classifierTraditional, nn.CrossEntropyLoss(), optimizerTraditional, trainLoader, epoch)\n",
        "  testStatTraditional = test(classifierTraditional, nn.CrossEntropyLoss(), testLoader, epoch)\n",
        "  testOutTrad.append(testStatTraditional)\n",
        "\n",
        "#Comaprison Fuction\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "AwDE6meuSPt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1HqHG9ZUBeYzfTjMj6GevgGom6Fc3HAMt",
      "authorship_tag": "ABX9TyOGy9FzBAs/Y3HrhqNBbZwe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}